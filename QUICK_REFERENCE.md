# âš¡ QUICK START - Local Mistral 7B + Zuhre Planet CLI

## ğŸ¯ 3 Komut = BaÅŸÄ±nda HazÄ±r

### Terminal 1: AI Sunucusunu BaÅŸlat
```bash
ollama serve
```
âœ… Ã‡Ä±ktÄ±: `Listening on 127.0.0.1:11434`

### Terminal 2: Development
```bash
# OPTION A: Interactive Chat
npm run local-ai

# OPTION B: Direct Commands
python cli/local-ai.py feature "yeni Ã¶zellik"
python cli/local-ai.py fix "hata aÃ§Ä±klamasÄ±"
python cli/local-ai.py analyze
```

### Terminal 3: Docker Services
```bash
docker compose up
```

---

## ğŸ“‹ SÄ±k Komutlar

```bash
# Sohbet (en etkili)
npm run local-ai

# Kod analizi
python cli/local-ai.py analyze

# Feature geliÅŸtirme (full-stack)
python cli/local-ai.py feature "CanlÄ± sohbet"

# Hata dÃ¼zeltme
python cli/local-ai.py fix "type mismatch"

# Test yazma
python cli/local-ai.py test "auth endpoints"

# Database schema
python cli/local-ai.py schema "add fields"

# Help
python cli/local-ai.py help
```

---

## ğŸ“ KonuÅŸma Ã–rnekleri

### Ã–rnek 1: Feature GeliÅŸtir
```bash
python cli/local-ai.py feature "Video upload sistemi - S3 integrations"
```
Ã‡Ä±ktÄ±: Kod, schema, router, component, types - hepsi!

### Ã–rnek 2: Interactive Chat
```bash
npm run local-ai

ğŸ¤– You: Escort profili nasÄ±l yapÄ±lÄ±r?
ğŸ¤” Assistant: React component, database schema...

ğŸ¤– You: 3D avatar ekle
ğŸ¤” Assistant: Three.js ile...

ğŸ¤– You: NSFW content handling
ğŸ¤” Assistant: (hiÃ§bir kÄ±sÄ±tlama yok - tam aÃ§Ä±klama)
```

### Ã–rnek 3: Hata DÃ¼zelt
```bash
python cli/local-ai.py fix "router.ts'de circular dependency"
```

---

## âœ… Kurulum Checklist

```bash
# 1. Ollama Ä°ndir
https://ollama.ai/download

# 2. Model Ä°ndir
ollama pull mistral

# 3. Dependencies
pip install -r cli/requirements.txt

# 4. Sunucuyu BaÅŸlat
ollama serve

# 5. Test Et
npm run local-ai
```

---

## ğŸ’ª Sistem Ã–zellikleri

âœ… **8 CPU, 16GB RAM, 157GB Disk** = Mistral 7B mÃ¼kemmel!

| Kapasite | Durum |
|----------|-------|
| CPU | âœ… 8 cores â†’ Yeterli |
| RAM | âœ… 16 GB â†’ Ä°deal |
| Disk | âœ… 157 GB â†’ Bol |
| GPU | âš ï¸ Intel UHD â†’ CPU OK |

---

## ğŸ” Privacy & Features

âœ… **Tamamen Local**
âœ… **NSFW KÄ±sÄ±tlamasÄ± YOK**
âœ… **AÃ§Ä±k Kaynak**
âœ… **HiÃ§bir API Key Gerekli DeÄŸil**
âœ… **Adult Content Support**

---

## ğŸš¨ HÄ±zlÄ± Ã‡Ã¶zÃ¼mler

| Problem | Ã‡Ã¶zÃ¼m |
|---------|-------|
| "Connection refused" | `ollama serve` baÅŸlat |
| Model yavaÅŸ | BaÅŸka programlarÄ± kapat |
| High RAM usage | Normal - Mistral 7B = 8-12GB |
| "model not found" | `ollama pull mistral` Ã§alÄ±ÅŸtÄ±r |

---

## ğŸ“Š Komut SeÃ§me Rehberi

```
Ne istiyorsun?

â†’ Sohbet / Soru sor
  npm run local-ai

â†’ Kod geliÅŸtir
  python cli/local-ai.py feature "..."

â†’ Hata bul / dÃ¼zelt
  python cli/local-ai.py fix "..."

â†’ Test yaz
  python cli/local-ai.py test "..."

â†’ Database update
  python cli/local-ai.py schema "..."
```

---

## ğŸ¯ Production Workflow

```
1. ollama serve (Terminal 1)

2. npm run local-ai (Terminal 2)
   ğŸ¤– You: KullanÄ±cÄ± profili sayfasÄ±

3. docker compose up (Terminal 3)

4. GeliÅŸtir, test et, deploy et!
```

---

## ğŸ“š Daha Fazla Info

- `MISTRAL_SETUP.md` - DetaylÄ± kurulum
- `LOCAL_MODEL_SETUP.md` - Model konfigÃ¼rasyonu
- `QUICKSTART.md` - Genel baÅŸlangÄ±Ã§
- `CLI_SETUP_GUIDE.md` - CLI detaylar

---

**TamamÄ± hazÄ±r! BaÅŸla!** ğŸš€

```bash
ollama serve
npm run local-ai
```
