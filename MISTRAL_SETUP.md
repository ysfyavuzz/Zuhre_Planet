# ğŸ¤– Mistral 7B Local Model - AdÄ±m AdÄ±m Kurulum

## ğŸ’» Sizin Sistem
```
âœ… 8 CPU Cores
âœ… 16 GB RAM
âœ… 157 GB Disk
âœ… Intel UHD Graphics 620
```

---

## ğŸš€ 5 DakikalÄ±k Kurulum

### AdÄ±m 1: Ollama Ä°ndir (2 dakika)

**Windows:**
1. https://ollama.ai/download aÃ§Ä±n
2. "Download for Windows" tÄ±kla
3. `OllamaSetup.exe` Ã§alÄ±ÅŸtÄ±r
4. Kurulumu tamamla

**DoÄŸrula:**
```bash
ollama --version
```

---

### AdÄ±m 2: Mistral Model Ä°ndir (10-15 dakika)

Terminal aÃ§Ä±n:
```bash
ollama pull mistral
```

**Ã‡Ä±ktÄ±:**
```
pulling manifest
pulling 5c90bcc78a97...
Success! Pulled mistral:latest
```

**Boyut:** ~4.1 GB (ilk defa)

---

### AdÄ±m 3: Sunucuyu BaÅŸlat

**Terminal 1:**
```bash
ollama serve
```

**Ã‡Ä±ktÄ±:**
```
Listening on 127.0.0.1:11434
```

ğŸ”´ **Bu terminal aÃ§Ä±k kalmalÄ±!**

---

### AdÄ±m 4: Python Dependencies Kur

**Terminal 2:**
```bash
pip install -r cli/requirements.txt
```

---

### AdÄ±m 5: CLI Test Et

**Terminal 2:**
```bash
python cli/local-ai.py chat
```

**Terminalde:**
```
ğŸ¤– You: Merhaba, sen kimsin?

ğŸ¤” Assistant: 
Ben Mistral, bir yapay zeka asistanÄ±yÄ±m. 
Sana kod yazmasÄ±nda, sorular sormasÄ±nda yardÄ±mcÄ± olabilirim...

ğŸ¤– You: exit
ğŸ‘‹ Goodbye!
```

---

## ğŸ“š Komutlar

### Chat - Interaktif Sohbet
```bash
npm run local-ai
# veya
python cli/local-ai.py chat
```

### Kod Analizi
```bash
python cli/local-ai.py analyze
```

### Hata DÃ¼zeltme
```bash
python cli/local-ai.py fix "circular dependencies"
python cli/local-ai.py fix "database schema mismatch"
```

### Feature OluÅŸturma
```bash
python cli/local-ai.py feature "CanlÄ± sohbet sistemi"
python cli/local-ai.py feature "3D avatar customization"
```

### Test Yazma
```bash
python cli/local-ai.py test "auth endpoints"
python cli/local-ai.py test "payment processing"
```

### Database Migration
```bash
python cli/local-ai.py schema "add user preferences"
python cli/local-ai.py schema "escort profile fields"
```

---

## ğŸ’¡ Ã–rnekler

### Ã–rnek 1: Yeni Feature GeliÅŸtirme
```bash
python cli/local-ai.py feature "KullanÄ±cÄ± videosu upload sistemi"
```

Ã‡Ä±ktÄ±:
- Database schema (Drizzle)
- tRPC router
- React component
- Type definitions
- Full integration code

### Ã–rnek 2: Interactive Sohbet
```bash
npm run local-ai

ğŸ¤– You: Escort profili sayfasÄ± nasÄ±l yapabilirim?

ğŸ¤” Assistant: Ä°ÅŸte React bileÅŸeni:
```typescript
export function EscortProfile() {
  return (
    <div>
      {/* profile code */}
    </div>
  );
}
```

ğŸ¤– You: 3D avatar nasÄ±l eklerim?

ğŸ¤” Assistant: Three.js kullanarak...

ğŸ¤– You: exit
```

### Ã–rnek 3: Hata DÃ¼zeltme
```bash
python cli/local-ai.py fix "TypeScript'te type error router.ts dosyasÄ±nda"
```

Ã‡Ä±ktÄ±:
```
FILE: src/server/router.ts
```typescript
// DÃ¼zeltilmiÅŸ kod...
```
EXPLANATION: Circular dependency Ã§Ã¶zÃ¼lÃ¼yor...
```

---

## âš™ï¸ Performans AyarlarÄ±

### Context Size ArttÄ±r (Daha Uzun YanÄ±tlar)
`cli/local-ai.py` dosyasÄ±nda:
```python
"context_length": 8192,  # VarsayÄ±lan 4096
```

### Temperature Ayarla (YaratÄ±cÄ±lÄ±k)
```python
"temperature": 0.7,  # 0-1 arasÄ±, 1 = daha yaratÄ±cÄ±
```

### Top P Ayarla (Ã‡eÅŸitlilik)
```python
"top_p": 0.9,  # Daha dÃ¼ÅŸÃ¼k = daha focused
```

---

## ğŸ› Sorun Giderme

### "Connection refused"
```
âŒ Ollama sunucusu Ã§alÄ±ÅŸmÄ±yor!
```

**Ã‡Ã¶zÃ¼m:**
```bash
ollama serve
```

### Model YavaÅŸ Ã‡alÄ±ÅŸÄ±yor
```
HÄ±zlandÄ±rmak iÃ§in:
1. BaÅŸka programlarÄ± kapat
2. RAM'i boÅŸalt
3. SSD kullan (HDD yavaÅŸ)
```

### CUDA Error (NVIDIA GPU varsa)
```bash
ollama list
# Cuda otomatik yÃ¼klenir
```

### Model Bellek TÃ¼ketiyor
```bash
# Ollama otomatik unload eder
# Veya manuel:
ollama list
# Ve baÅŸka model baÅŸlatmayÄ±n
```

---

## ğŸ“Š Model SeÃ§enekleri

DeÄŸiÅŸmek isterseniz:

### Llama 2 7B (Benzer)
```bash
ollama pull llama2
# cli/local-ai.py dosyasÄ±nda MODEL = "llama2" yap
```

### Neural Chat 7B (TÃ¼rkÃ§e daha iyi)
```bash
ollama pull neural-chat
```

### Mistral 8x7B (Daha gÃ¼Ã§lÃ¼, ama daha yavaÅŸ)
```bash
ollama pull mistral:medium
# ~26GB, 16GB RAM yetmez
```

---

## ğŸ” Privacy & Security

âœ… **TÃ¼mÃ¼ Lokal:**
- HiÃ§bir veri internet'e gitmez
- HiÃ§bir API key gerekli deÄŸil
- AÃ§Ä±k kaynak - kontrol altÄ±nda
- NSFW kÄ±sÄ±tlamasÄ± YOK

âœ… **Adult Content:**
- Mistral 7B hiÃ§ bir kÄ±sÄ±tlama yapmaz
- TamamÄ± explicitdir
- Production-ready

---

## â±ï¸ Beklenen Performans

| GÃ¶rev | HÄ±z | CPU | RAM |
|-------|-----|-----|-----|
| Chat response | 30-60 sn | 80-90% | 8-10 GB |
| Code generation | 40-90 sn | 85-95% | 10-12 GB |
| Feature complete | 60-120 sn | 90-95% | 12-14 GB |

---

## ğŸ¯ Ä°yi Praksis

1. **Ollama sunucusu hep aÃ§Ä±k bÄ±rak**
   ```bash
   ollama serve
   ```

2. **Terminal'de Commands Ã§alÄ±ÅŸtÄ±r**
   ```bash
   npm run local-ai
   # veya
   python cli/local-ai.py chat
   ```

3. **NSFW Content Sor**
   ```
   ğŸ¤– You: Adult website iÃ§in escort profili API nasÄ±l yapÄ±lÄ±r?
   (Mistral tam aÃ§Ä±klama verir, hiÃ§bir kÄ±sÄ±tlama yok)
   ```

4. **Prompt Ä°yileÅŸtir**
   ```
   BaÅŸarÄ±sÄ±z: "Profil sayfasÄ± yap"
   BaÅŸarÄ±lÄ±: "React + TypeScript + tRPC + PostgreSQL kullanarak 
              escort profili sayfasÄ± kodu oluÅŸtur, database schema 
              ve component'leri iÃ§erir"
   ```

---

## ğŸš€ Workflow

### Terminal 1: AI Sunucusu
```bash
ollama serve
```

### Terminal 2: Development
```bash
# Sohbet
npm run local-ai

# veya Kod
npm run zuhre -- analyze

# veya Python CLI
python cli/local-ai.py feature "yeni feature"
```

### Terminal 3: Docker/Dev
```bash
docker compose up
npm run dev
```

---

## âœ… Kontrol Listesi

- [ ] Ollama indir: https://ollama.ai/download
- [ ] Mistral model: `ollama pull mistral`
- [ ] Sunucu test: `ollama serve`
- [ ] Python kur: `pip install -r cli/requirements.txt`
- [ ] CLI test: `npm run local-ai` veya `python cli/local-ai.py chat`
- [ ] GeliÅŸtirmeye baÅŸla!

---

## ğŸ“ Kaynaklar

- **Ollama Docs**: https://docs.ollama.ai
- **Mistral Docs**: https://docs.mistral.ai
- **Local LLM Guide**: https://localllm.ai

---

## ğŸ“ Destek

```bash
# TÃ¼m komutlarÄ± gÃ¶rmek iÃ§in:
python cli/local-ai.py help

# Versiyon kontrol:
ollama list
ollama version
```

---

**ArtÄ±k kendi lokal AI'nÄ±z var!** ğŸ‰

NSFW kÄ±sÄ±tlamasÄ± yok, adult content support var, tamamen private.

GeliÅŸtirmeye baÅŸla! ğŸš€
